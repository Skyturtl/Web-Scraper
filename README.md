# Web-Scraper
For HKUST class COMP4321

Prerequisites:
Ensure you have the following installed on your system before running the project:
1.Python 3.x
2.Required Python libraries:
  **requests
  beautifulsoup4
  nltk
  sqlite3**
3.Internet connection (for downloading NLTK tokenizer)

Project Structure:
|-- main.py               # Main execution file
|-- scraper.py            # Web crawler (spider) implementation
|-- database.py           # Database operations (SQLite)
|-- stopwords.txt         # List of stopwords for filtering
|-- scraper.db            # SQLite database (generated after execution)
|-- spider_result.py      # Generates the results file
|-- spider_result.txt     # Final processed results (generated by spider_result.py)

How to Build and Execute:
Step 1: Setup Database
Ensure scraper.db does not exist if you want a fresh run.
Run main.py to initialize the database and start the web crawler: 
**python main.py**
This will:
Create the necessary tables in the SQLite database.
Start crawling from the given seed URL (defined in main.py).
Store the extracted data (links, keywords, parent-child relationships) in scraper.db.

Step 2: Generate Spider Result
Once the crawler has indexed the pages, generate the spider_result.txt output file by running:
**python spider_result.py**
This will:
Fetch indexed data from the database.
Generate a formatted spider_result.txt file with pages, keywords, and child links.

Step 3: View Output
The scraper.db file contains indexed data.
The spider_result.txt file contains the final results in the required format.
